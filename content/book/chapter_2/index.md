---
title: Running Models Local
description: Learn how to run AI models locally using user-friendly tools like LM Studio and Ollama.
keywords: running models, local ai, lm studio, ollama, docker llm
---

In this chapter, you'll discover the exciting world of running AI models directly on your computer. Weâ€™ll explore why doing so can be incredibly beneficial for developers and enthusiasts alike. You'll learn about the vibrant open-source community that supports a wide range of models designed to work seamlessly in local environments.

I'll introduce you to my two go-to tools:

- **LM Studio**: A sleek, intuitive interface that makes managing AI models and interacting with them through chat interfaces a breeze.
  
- **Ollama**: An innovative solution for running large language models locally. It offers an OpenAPI-compatible API, making it easy to integrate these powerful models into your projects.

By the end of this chapter, you'll be equipped with the knowledge to set up and run AI models on your local machine, opening up a world of possibilities for experimentation and innovation. Dive in and see how running models locally can enhance your AI development experience!