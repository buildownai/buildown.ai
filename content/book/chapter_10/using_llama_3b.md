---
title: Evaluating Llama 3.2 3B
description: Explore the evaluation of the custom model `buildownai/llama3b` based on **Llama 3.2 3B** with a focus on its performance at different temperatures.
keywords:
- Llama 3.2 3B
- Custom Model Evaluation
- Temperature Settings
- Data Generation
- Query Results
---

In this chapter, you'll dive into the evaluation of our custom AI model `buildownai/llama3b`, which is based on **Llama 3.2 3B** and has a large context size for better performance during inference. We will explore how adjusting the temperature parameter affects the model's output quality and reliability.

You'll learn about setting up the model with specific configurations, such as increasing its attention span to handle more context. Then, weâ€™ll evaluate the model at two different temperatures: **0.01** and **1**, observing how these settings impact data generation and query results.

Discover insights into the model's performance in generating precise answers and handling complex queries related to a TypeScript backend framework called PURISTA. We'll also discuss common issues like hallucinations, broken links, and context differentiation challenges that arise at higher temperatures.

Join us as we uncover the nuances of fine-tuning AI models for optimal usability and reliability!