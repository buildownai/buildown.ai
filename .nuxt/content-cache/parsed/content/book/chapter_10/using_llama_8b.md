{"parsed":{"_path":"/book/chapter_10/using_llama_8b","_dir":"chapter_10","_draft":false,"_partial":false,"_locale":"","title":"Evaluating Llama 3.1 8B","description":"This chapter explores how different settings affect the performance of the Llama 3.1 8B model when creating question-answer pairs and generating responses.","keywords":"Llama 3.1, AI models, evaluation, temperature setting, data generation, query results","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this chapter, you'll dive into the fascinating world of tweaking AI models to get the best out of them! We’ll focus on a specific model called "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Llama 3.1 8B"}]},{"type":"text","value":" and see how adjusting its settings can change its behavior."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"First, we’ll set the temperature to "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"0.01"}]},{"type":"text","value":", which is like turning down the dial for creativity in your AI assistant. You'll learn about generating data, such as question-answer pairs, and see how precise but sometimes less natural these answers become. We’ll also look at query results to understand when the model performs well and where it falls short."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Next, we crank up the temperature to "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"1"}]},{"type":"text","value":", which is like letting the AI go wild with creativity! You'll explore how this setting can lead to a wide range of outcomes—some questions get perfect answers while others might not be answered correctly at all. We’ll also discuss data generation quality and query results, highlighting when the model benefits from additional context."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"By the end of this chapter, you’ll have a better understanding of how different settings impact your AI’s performance and know what to expect when fine-tuning models for specific tasks. Ready to see Llama 3.1 8B in action? Let's dive in!"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:book:chapter_10:using_llama_8b.md","_source":"content","_file":"book/chapter_10/using_llama_8b.md","_stem":"book/chapter_10/using_llama_8b","_extension":"md","sitemap":{"loc":"/book/chapter_10/using_llama_8b"}},"hash":"OxE1MmZBDS"}