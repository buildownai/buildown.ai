{"parsed":{"_path":"/book/chapter_10/use_full_context_size","_dir":"chapter_10","_draft":false,"_partial":false,"_locale":"","title":"Using Full Context Size","description":"Learn how to adjust the context size for your AI models and troubleshoot issues related to large document processing.","keywords":["full context size, Ollama API, Modelfile, Docker, streaming response, temperature setting, language model debugging"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this chapter, you'll dive into adjusting the context size of your AI models. You’ll learn why a larger context size is crucial for handling extensive documents and how to set it up using the Ollama API. We’ll walk through creating a custom "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"Modelfile"}]},{"type":"text","value":" with Docker to increase the token limit from 2048 to 131,072 tokens."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You'll also explore troubleshooting techniques when your model gets stuck in an infinite loop or generates repetitive text. Discover how to enable streaming responses for real-time logging and debugging. We’ll cover adjusting parameters like "},{"type":"element","tag":"code","props":{"className":[]},"children":[{"type":"text","value":"temperature"}]},{"type":"text","value":" to improve model performance and prevent repetition issues."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"By the end of this chapter, you’ll have a solid understanding of how to optimize your AI models for better performance with large datasets."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:book:chapter_10:use_full_context_size.md","_source":"content","_file":"book/chapter_10/use_full_context_size.md","_stem":"book/chapter_10/use_full_context_size","_extension":"md","sitemap":{"loc":"/book/chapter_10/use_full_context_size"}},"hash":"DR3Cb0BwzW"}